Create:
    md5sum *.csv > allclean.md5
    tar cf allclean.tar allclean
    xz -z -k -9e -T 0 allclean.tar
    base64 -w 0 allclean.tar.xz > allclean.txz.b64
    rm allclean.tar
    mkdir allclean_b64_split
    cd allclean_b64_split
    split -a 3 -b 10M -d ../allclean.txz.b64 allclean.tx64. & \
        pv -d $(pgrep split):0
    ls > index.txt
    sed -i -ne '/index/ d; p' index.txt

Push to github

Download:
GH='https://raw.githubusercontent.com/xxc3nsoredxx/dissconnect_data'
INDEX_COMMIT='2afe781db2d2a17b9efab0c50294f8ffb554f6ac'
DATA_COMMIT='ad4dfb51adf657d23e173f4a28a9b740b83c2841'
FOLDER='allclean_b64_split'

# Probe for the download ok marker file
# Deleting the marker will prompt a re-setup of the datasets
if [ ! -e dl.ok ]; then
    # Gets the index of files to download and passes it on
    ( (wget -nv -O - --show-progress $GH/$INDEX_COMMIT/$FOLDER/index.html | \
        # Downloads the required files and passes them on as a constant(ish)
        # stream of data
        wget -nv -i - --force-html -B $GH/$DATA_COMMIT/$FOLDER/ \
        -O - --show-progress | \
        # Once enough data has stramed in:
        #   * Undoes the base64 encoding and passes the result to tar
        #   * tar both un-xz's and un-tars a dataset as soon as it can
        base64 -d -w 0 | tar xJU --strip=1) && \
        # Once all the datasets are downloaded, it compares the downloaded md5
        # hashes for each and creates the marker file on success
        md5sum -c allclean.md5 && touch dl.ok) || \
    (echo "Error downloading files, try again later"; rm *all*; exit 1)

    # If the dowload was a success, create the merged csv file used later on
    cat {*1.,*2*.}csv > output_allclean_merged.csv
fi
